{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, yaml\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the credentials required for OPEN AI/ TOGETHER\n",
    "with open(\"credential.yaml\", 'r') as file:\n",
    "    credentials= yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "os.environ['OPENAI_API_KEY']= credentials['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building client \n",
    "client= OpenAI() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating responses based on the user messages\n",
    "def complete_response(prompt):\n",
    "    response= client.chat.completions.create(        \n",
    "        model='gpt-3.5-turbo',\n",
    "        messages= [{\"role\": \"system\",\"content\" : \"You are a helpful assistant to generate responses on the given prompt.\"},\n",
    "                   {\"role\": \"user\", \"content\": prompt}\n",
    "                   ],\n",
    "        temperature=0.5,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return str(response.choices[0].message.content)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "context ='''A large language model (LLM) is a language model notable for its ability to achieve general-purpose language generation and other natural language processing tasks such as classification. LLMs acquire these abilities by learning statistical relationships from text documents during a computationally intensive self-supervised and semi-supervised training process.[1] LLMs can be used for text generation, a form of generative AI, by taking an input text and repeatedly predicting the next token or word.[2]\n",
    "LLMs are artificial neural networks. The largest and most capable, as of March 2024, are built with a decoder-only transformer-based architecture while some recent implementations are based on other architectures, such as recurrent neural network variants and Mamba (a state space model).[3][4][5]\n",
    "Up to 2020, fine tuning was the only way a model could be adapted to be able to accomplish specific tasks. Larger sized models, such as GPT-3, however, can be prompt-engineered to achieve similar results.[6] They are thought to acquire knowledge about syntax, semantics and \"ontology\" inherent in human language corpora, but also inaccuracies and biases present in the corpora.[7]\n",
    "Some notable LLMs are OpenAI's GPT series of models (e.g., GPT-3.5 and GPT-4, used in ChatGPT and Microsoft Copilot), Google's PaLM and Gemini (the latter of which is currently used in the chatbot of the same name), xAI's Grok, Meta's LLaMA family of open-source models, Anthropic's Claude models, and Mistral AI's open source models. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1=f\"identify the most important points from the below context : {context}\"\n",
    "output= complete_response(prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Large language models (LLMs) are capable of general-purpose language generation and natural language processing tasks like classification by learning statistical relationships from text documents.\n",
      "2. LLMs are artificial neural networks, with the most advanced models using a decoder-only transformer-based architecture.\n",
      "3. Prior to 2020, fine-tuning was the primary method to adapt models for specific tasks, but newer, larger models like GPT-3 can be prompt-engineered for similar results.\n",
      "4. LLMs are believed to learn syntax, semantics, and ontology from human language corpora, but may also inherit inaccuracies and biases present in the data.\n",
      "5. Notable LLMs include OpenAI's GPT series, Google's PaLM and Gemini, xAI's Grok, Meta's LLaMA models, Anthropic's Claude models, and Mistral AI's open source models.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large language models (LLMs) have revolutionized the field of natural language processing by showcasing their capabilities in general-purpose language generation and various tasks such as classification. These models operate by learning statistical relationships from text documents, enabling them to understand and generate human-like language patterns effectively.\n",
      "\n",
      "Artificial neural networks form the foundation of LLMs, with the most advanced models adopting a decoder-only transformer-based architecture. This architecture has significantly enhanced the performance of LLMs, enabling them to process and generate text with exceptional accuracy and fluency.\n",
      "\n",
      "Previously, fine-tuning was the primary technique used to tailor models for specific tasks. However, with the advent of newer and larger models like GPT-3, prompt-engineering has emerged as an effective method to achieve similar results. This approach allows users to guide the model's responses by providing specific prompts.\n",
      "\n",
      "While LLMs are known to learn syntax, semantics, and ontology from vast human language corpora, they are also susceptible to inheriting inaccuracies and biases present in the training data. This raises concerns about the potential propagation of biases in the language generated by these models, highlighting the importance of ethical considerations in their development and deployment.\n",
      "\n",
      "Several notable LLMs have emerged from leading organizations such as OpenAI, Google, xAI, Meta, Anthropic, and Mistral AI. Examples include OpenAI's GPT series, Google's PaLM and Gemini, xAI's Grok, Meta's LLaMA models, Anthropic's Claude models, and Mistral AI's open-source models. These models continue to push the boundaries of language processing capabilities and pave the way for exciting advancements in artificial intelligence.\n"
     ]
    }
   ],
   "source": [
    "prompt2 =f\"By following the given points, write a simple essay on the given large language models. {output}\"\n",
    "print(complete_response(prompt2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
